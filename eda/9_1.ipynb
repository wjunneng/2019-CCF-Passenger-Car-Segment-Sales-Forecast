{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/wjunneng/Python/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:21: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n/home/wjunneng/Python/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/home/wjunneng/Python/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:60: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n/home/wjunneng/Python/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:62: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 36960 entries, 0 to 36959\nData columns (total 7 columns):\nadcode         36960 non-null int64\nbodyType       36960 non-null object\nmodel          36960 non-null object\nprovince       36960 non-null object\nregMonth       36960 non-null int64\nregYear        36960 non-null int64\nsalesVolume    31680 non-null float64\ndtypes: float64(1), int64(3), object(3)\nmemory usage: 2.0+ MB\nNone\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 36960 entries, 0 to 36959\nData columns (total 6 columns):\nadcode         36960 non-null int64\nbodyType       36960 non-null object\nmodel          36960 non-null object\nprovince       36960 non-null object\nsalesVolume    31680 non-null float64\ndate           36960 non-null object\ndtypes: float64(1), int64(1), object(4)\nmemory usage: 1.7+ MB\nNone\n   adcode bodyType             model province  salesVolume       date\n0  310000      SUV  3c974920a76ac9c1       上海        292.0 2016-01-01\n1  530000      SUV  3c974920a76ac9c1       云南        466.0 2016-01-01\n2  150000      SUV  3c974920a76ac9c1      内蒙古        257.0 2016-01-01\n3  110000      SUV  3c974920a76ac9c1       北京        408.0 2016-01-01\n4  510000      SUV  3c974920a76ac9c1       四川        610.0 2016-01-01\n{'3c974920a76ac9c1': 1, '3d7554f1f56dd664': 2, '2d0d2c3403909fdb': 3, 'a28bb927b6fcb33c': 4, '17bc272c93f19d56': 5, '2a2ab41f8f6ff1cb': 6, 'c06a2a387c0ee510': 7, '7023efdab9cedc03': 8, 'af6f4f548684e14d': 9, '7cf283430b3b5e38': 10, 'd4efbebb087fd03f': 11, '7245e0ee27b195cd': 12, '8c915fe4632fb9fa': 13, '6155b214590c66e6': 14, '28e29f2c03dcd84c': 15, '37aa9169b575ef79': 16, '63065128401bb3ff': 17, 'ea489c253676aafc': 18, 'cd5841d44fd7625e': 19, 'b25c4e2e3856af22': 20, '4a103c30d593fbbe': 21, '7a7885e2d7c00bcf': 22, '346393c2c6305fb1': 23, '02aab221aabc03b9': 24, '5d7fb682edd0f937': 25, 'a207df29ec9583f0': 26, 'b4be3a4917289c82': 27, 'ef76a85c4b39f693': 28, 'bb9fbec9a2833839': 29, 'da457d15788fe8ee': 30, '6858d6dfe680bdf7': 31, '79de4e4b24c35b04': 32, '12f8b7e14947c34d': 33, '04e66e578f653ab9': 34, 'dff803b4024d261d': 35, '61e73e32ad101892': 36, 'a432c483b5beb856': 37, '0797526c057dcf5b': 38, '936168bd4850913d': 39, 'cc21c7e91a3b5a0c': 40, '7aab7fca2470987e': 41, 'fde95ea242abd896': 42, '97f15de12cfabbd5': 43, 'f5d69960089c3614': 44, '5b1c11c3efed5312': 45, '17363f08d683d52b': 46, '06880909932890ca': 47, '9c1c7ee8ebdda299': 48, 'c6833cb891626c17': 49, '3e21824be728cbec': 50, 'f8a6975573af1b33': 51, '54fc07138d70374c': 52, '212083a9246d2fd3': 53, '4f79773e600518a6': 54, 'fc32b1a017b34efe': 55, 'feabbf46658382b9': 56, 'f270f6a489c6a9d7': 57, 'd0f245b8781e3631': 58, 'c6cd4e0e073f5ac2': 59}\n   adcode  bodyType  model province  salesVolume       date\n0  310000         2    1.0       上海        292.0 2016-01-01\n1  530000         2    1.0       云南        466.0 2016-01-01\n2  150000         2    1.0      内蒙古        257.0 2016-01-01\n3  110000         2    1.0       北京        408.0 2016-01-01\n4  510000         2    1.0       四川        610.0 2016-01-01\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "project_path = '/home/wjunneng/Ubuntu/2019-CCF-Passenger-Car-Segment-Sales-Forecast'\n",
    "\n",
    "# train_sales_data\n",
    "train_sales_data_path = project_path + '/data/original/train_sales_data.csv'\n",
    "# train_search_data\n",
    "train_search_data_path = project_path + '/data/original/train_search_data.csv'\n",
    "# train_user_reply_data\n",
    "train_user_reply_data = project_path + '/data/original/train_user_reply_data.csv'\n",
    "# evaluation_public\n",
    "evaluation_public = project_path + '/data/original/evaluation_public.csv'\n",
    "# submit_example.csv\n",
    "submit_example = project_path + '/data/original/submit_example.csv'\n",
    "\n",
    "train_sales_data = pd.read_csv(train_sales_data_path)\n",
    "# train_search_data = pd.read_csv(train_search_data_path)\n",
    "# train_user_reply_data = pd.read_csv(train_user_reply_data)\n",
    "evaluation_public = pd.read_csv(evaluation_public)\n",
    "\n",
    "data = pd.concat([train_sales_data, evaluation_public], axis=0, ignore_index=True)\n",
    "data['bodyType'] = data['model'].map(train_sales_data.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "data.drop(labels='forecastVolum', axis=1, inplace=True)\n",
    "data.drop(labels='id', axis=1, inplace=True)\n",
    "print(data.info())\n",
    "\n",
    "data['date'] = data['regYear'].astype(str) + '-' + data['regMonth'].astype(str)\n",
    "data.drop(labels='regYear', axis=1, inplace=True)\n",
    "data.drop(labels='regMonth', axis=1, inplace=True)\n",
    "print(data.info())\n",
    "\n",
    "import datetime\n",
    "\n",
    "data['date'] = data['date'].apply(lambda x: datetime.datetime(year=int(x.split('-')[0]), month=int(x.split('-')[1]), day=1))\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "data['bodyType'] = data['bodyType'].apply(lambda x: 1 if x == 'Sedan' else x)\n",
    "data['bodyType'] = data['bodyType'].apply(lambda x: 2 if x == 'SUV' else x)\n",
    "data['bodyType'] = data['bodyType'].apply(lambda x: 3 if x == 'MPV' else x)\n",
    "data['bodyType'] = data['bodyType'].apply(lambda x: 4 if x == 'Hatchback' else x)\n",
    "\n",
    "model = dict(zip(data['model'].unique(), range(1, data['model'].nunique())))\n",
    "\n",
    "print(model)\n",
    "\n",
    "data['model'] = data['model'].map(model)\n",
    "print(data.head())\n",
    "\n",
    "data.drop(labels='province', axis=1, inplace=True)\n",
    "data['adcode'] = data['adcode'].apply(lambda x: int(str(x)[:2]))\n",
    "\n",
    "X_train = pd.DataFrame(columns=data.columns)\n",
    "# X_valid = pd.DataFrame(columns=data.columns)\n",
    "X_test = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "for key, value in data.groupby(by=['bodyType', 'model', 'adcode']):\n",
    "    value.sort_values(by='date', inplace=True)\n",
    "    value.reset_index(inplace=True)\n",
    "    X_train = pd.concat([X_train, value.loc[:23, :]], axis=0, ignore_index=True)\n",
    "    # X_valid = pd.concat([X_valid, value.loc[20:23, :]], axis=0, ignore_index=True)\n",
    "    X_test = pd.concat([X_test, value.loc[24:, :]], axis=0, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path = '/home/wjunneng/Ubuntu/2019-CCF-Passenger-Car-Segment-Sales-Forecast/demo/lstm/data'\n",
    "\n",
    "X_train = X_train[['date', 'adcode', 'bodyType', 'model', 'salesVolume']]\n",
    "# X_valid = X_valid[['date', 'adcode', 'bodyType', 'model', 'salesVolume']]\n",
    "X_test = X_test[['date', 'adcode', 'bodyType', 'model', 'salesVolume']]\n",
    "\n",
    "X_train.to_csv(path_or_buf=path+'/X_train.csv', index=None, encoding='utf-8')\n",
    "# X_valid.to_csv(path_or_buf=path+'/X_valid.csv', index=None, encoding='utf-8')\n",
    "X_test.to_csv(path_or_buf=path+'/X_test.csv', index=None, encoding='utf-8')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/wjunneng/Python/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/preprocessing/data.py:355: RuntimeWarning: All-NaN slice encountered\n  data_min = np.nanmin(X, axis=0)\n/home/wjunneng/Python/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: RuntimeWarning: All-NaN slice encountered\n  data_max = np.nanmax(X, axis=0)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Train on 25960 samples, validate on 5192 samples\nEpoch 1/10\n",
      "\r 1024/25960 [>.............................] - ETA: 56s - loss: 0.2161 - ce: 0.6943",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8192/25960 [========>.....................] - ETA: 5s - loss: 0.2145 - ce: 0.6918 ",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15360/25960 [================>.............] - ETA: 1s - loss: 0.2131 - ce: 0.6896",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22528/25960 [=========================>....] - ETA: 0s - loss: 0.2124 - ce: 0.6876",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25960/25960 [==============================] - 3s 110us/step - loss: 0.2119 - ce: 0.6866 - val_loss: 0.1933 - val_ce: 0.6792\n",
      "Epoch 2/10\n\r 1024/25960 [>.............................] - ETA: 0s - loss: 0.2085 - ce: 0.6784",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8192/25960 [========>.....................] - ETA: 0s - loss: 0.2072 - ce: 0.6765",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15360/25960 [================>.............] - ETA: 0s - loss: 0.2057 - ce: 0.6745",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22528/25960 [=========================>....] - ETA: 0s - loss: 0.2047 - ce: 0.6725",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25960/25960 [==============================] - 0s 9us/step - loss: 0.2043 - ce: 0.6715 - val_loss: 0.1859 - val_ce: 0.6645\n",
      "Epoch 3/10\n\r 1024/25960 [>.............................] - ETA: 0s - loss: 0.1982 - ce: 0.6631",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7168/25960 [=======>......................] - ETA: 0s - loss: 0.1986 - ce: 0.6612",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13312/25960 [==============>...............] - ETA: 0s - loss: 0.1981 - ce: 0.6594",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20480/25960 [======================>.......] - ETA: 0s - loss: 0.1970 - ce: 0.6570",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25960/25960 [==============================] - 0s 9us/step - loss: 0.1962 - ce: 0.6552 - val_loss: 0.1776 - val_ce: 0.6477\n",
      "Epoch 4/10\n\r 1024/25960 [>.............................] - ETA: 0s - loss: 0.1918 - ce: 0.6457",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7168/25960 [=======>......................] - ETA: 0s - loss: 0.1904 - ce: 0.6432",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14336/25960 [===============>..............] - ETA: 0s - loss: 0.1889 - ce: 0.6405",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20480/25960 [======================>.......] - ETA: 0s - loss: 0.1877 - ce: 0.6381",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25960/25960 [==============================] - 0s 9us/step - loss: 0.1865 - ce: 0.6358 - val_loss: 0.1668 - val_ce: 0.6261\n",
      "Epoch 5/10\n\r 1024/25960 [>.............................] - ETA: 0s - loss: 0.1810 - ce: 0.6241",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8192/25960 [========>.....................] - ETA: 0s - loss: 0.1785 - ce: 0.6192",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15360/25960 [================>.............] - ETA: 0s - loss: 0.1760 - ce: 0.6143",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22528/25960 [=========================>....] - ETA: 0s - loss: 0.1736 - ce: 0.6096",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25960/25960 [==============================] - 0s 9us/step - loss: 0.1723 - ce: 0.6069 - val_loss: 0.1482 - val_ce: 0.5884\n",
      "Epoch 6/10\n\r 1024/25960 [>.............................] - ETA: 0s - loss: 0.1615 - ce: 0.5885",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7168/25960 [=======>......................] - ETA: 0s - loss: 0.1580 - ce: 0.5773",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14336/25960 [===============>..............] - ETA: 0s - loss: 0.1544 - ce: 0.5690",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21504/25960 [=======================>......] - ETA: 0s - loss: 0.1495 - ce: 0.5582",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25960/25960 [==============================] - 0s 9us/step - loss: 0.1464 - ce: 0.5512 - val_loss: 0.1063 - val_ce: 0.5010\n",
      "Epoch 7/10\n\r 1024/25960 [>.............................] - ETA: 0s - loss: 0.1242 - ce: 0.5027",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8192/25960 [========>.....................] - ETA: 0s - loss: 0.1221 - ce: 0.4945",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14336/25960 [===============>..............] - ETA: 0s - loss: 0.1176 - ce: 0.4833",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21504/25960 [=======================>......] - ETA: 0s - loss: 0.1134 - ce: 0.4723",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25960/25960 [==============================] - 0s 9us/step - loss: 0.1107 - ce: 0.4655 - val_loss: 0.0418 - val_ce: 0.3414\n",
      "Epoch 8/10\n\r 1024/25960 [>.............................] - ETA: 0s - loss: 0.0942 - ce: 0.4280",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8192/25960 [========>.....................] - ETA: 0s - loss: 0.0889 - ce: 0.4163",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14336/25960 [===============>..............] - ETA: 0s - loss: 0.0859 - ce: 0.4109",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20480/25960 [======================>.......] - ETA: 0s - loss: 0.0832 - ce: 0.4066",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25960/25960 [==============================] - 0s 9us/step - loss: 0.0808 - ce: 0.4023 - val_loss: 0.0134 - val_ce: 0.2662\n",
      "Epoch 9/10\n\r 1024/25960 [>.............................] - ETA: 0s - loss: 0.0674 - ce: 0.3844",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8192/25960 [========>.....................] - ETA: 0s - loss: 0.0659 - ce: 0.3821",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14336/25960 [===============>..............] - ETA: 0s - loss: 0.0653 - ce: 0.3826",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21504/25960 [=======================>......] - ETA: 0s - loss: 0.0638 - ce: 0.3824",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25960/25960 [==============================] - 0s 9us/step - loss: 0.0630 - ce: 0.3833 - val_loss: 0.0089 - val_ce: 0.3023\n",
      "Epoch 10/10\n\r 1024/25960 [>.............................] - ETA: 0s - loss: 0.0567 - ce: 0.3753",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8192/25960 [========>.....................] - ETA: 0s - loss: 0.0569 - ce: 0.3864",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15360/25960 [================>.............] - ETA: 0s - loss: 0.0555 - ce: 0.3874",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22528/25960 [=========================>....] - ETA: 0s - loss: 0.0551 - ce: 0.3884",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25960/25960 [==============================] - 0s 9us/step - loss: 0.0547 - ce: 0.3896 - val_loss: 0.0085 - val_ce: 0.3645\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train = X_train.set_index('date')\n",
    "X_valid = X_valid.set_index('date')\n",
    "X_test = X_test.set_index('date')\n",
    "\n",
    "\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = sc.fit_transform(X_train.iloc[:,:].values)\n",
    "X_valid = sc.fit_transform(X_valid.iloc[:,:].values)\n",
    "X_test = sc.fit_transform(X_test.iloc[:,:].values)\n",
    "\n",
    "X_train, y_train = X_train[:,:-1], X_train[:,-1]\n",
    "X_val, y_val = X_valid[:,:-1], X_valid[:,-1]\n",
    "X_test, y_test = X_test[:,:-1], X_test[:,-1]\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "# Initialising RNN\n",
    "regressor = Sequential()\n",
    "# Adding the first LSTM layer and some Dropout regularization\n",
    "# Dropout regularization is added to avoid overfitting\n",
    "\n",
    "regressor.add(LSTM(units = 10, return_sequences = True, activation = 'relu', input_shape = (X_train.shape[1], 4)))\n",
    "regressor.add(Dropout(0.5))\n",
    "# adding a second LSTM layer and some dropout regularization\n",
    "regressor.add(LSTM(units = 10, return_sequences = True, activation = 'relu'))\n",
    "regressor.add(Dropout(0.5))\n",
    "# adding a fourth LSTM layer and some dropout regularization\n",
    "regressor.add(LSTM(units = 10, return_sequences = False, activation = 'relu'))\n",
    "regressor.add(Dropout(0.5))\n",
    "# Adding the output layer\n",
    "#regressor.add(Flatten())\n",
    "regressor.add(Dense(units=1, activation = 'sigmoid'))\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer='adam', \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=['crossentropy'])\n",
    "# Fitting the RNN to the training set\n",
    "history = regressor.fit(X_train, \n",
    "              y_train, \n",
    "              epochs = 10, \n",
    "              batch_size = 1024, \n",
    "              validation_data = (X_val, y_val),\n",
    "              verbose = 1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2.7303183e-01],\n       [2.0852444e-01],\n       [1.3154912e-01],\n       ...,\n       [7.1525574e-07],\n       [2.0861626e-07],\n       [0.0000000e+00]], dtype=float32)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 139
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted_sales = regressor.predict(X_test)\n",
    "predicted_sales\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(5192, 4) (5192, 1)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "(5192, 5)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 140
    }
   ],
   "source": [
    "# Reshape X_test for inverse scaling\n",
    "result = X_test.reshape((X_test.shape[0], X_test.shape[2]))\n",
    "print(result.shape, predicted_sales.shape)\n",
    "# Concatenate in the same order. In our example, values of weekly sales should be in the end. Hence result[:,:] followed by predicted_sales\n",
    "predicted_weekly_sales = np.concatenate((result, predicted_sales),axis=1)\n",
    "predicted_weekly_sales.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "predicted_weekly_sales = sc.inverse_transform(predicted_weekly_sales)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "predicted_weekly_sales = predicted_weekly_sales[:,4:5]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[nan],\n       [nan],\n       [nan],\n       ...,\n       [nan],\n       [nan],\n       [nan]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 143
    }
   ],
   "source": [
    "predicted_weekly_sales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-427c7da",
   "language": "python",
   "display_name": "PyCharm (2019-CCF-Passenger-Car-Segment-Sales-Forecast)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}